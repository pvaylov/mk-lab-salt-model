classes:

- system.linux.system.repo.mos9

- system.glusterfs.server.volume.glance
- system.glusterfs.server.volume.keystone
- system.glusterfs.server.cluster
- system.salt.control.virt
- system.salt.control.cluster.opencontrail_analytics_cluster
- system.salt.control.cluster.opencontrail_control_cluster
- system.salt.control.cluster.openstack_control_cluster
- system.salt.control.cluster.openstack_proxy_cluster
- system.salt.control.cluster.openstack_database_cluster
- system.salt.control.cluster.openstack_message_queue_cluster
- system.salt.control.cluster.openstack_telemetry_cluster
- system.salt.control.cluster.stacklight_server_cluster
- system.salt.control.cluster.stacklight_log_cluster
- system.salt.control.cluster.stacklight_telemetry_cluster
- cluster.mcp05-test
parameters:
  _param:
    cluster_vip_address: ${_param:infra_compute_address}
    cluster_node01_address: ${_param:infra_compute_node01_address}
    cluster_node02_address: ${_param:infra_compute_node02_address}
    cluster_node03_address: ${_param:infra_compute_node03_address}
    keepalived_vip_interface: eth1
    keepalived_vip_virtual_router_id: 69
  salt:
    control:
      size: #RAM 4096,8192,16384,32768,65536
      ##Default production sizing
        openstack.control:
          cpu: 8
          ram: 16384
          disk_profile: small
          net_profile: default
        openstack.database:
          cpu: 8
          ram: 8192
          disk_profile: large
          net_profile: default
        openstack.message_queue:
          cpu: 8
          ram: 16384
          disk_profile: small
          net_profile: default
        openstack.telemetry:
          cpu: 8
          ram: 16384
          disk_profile: xxlarge
          net_profile: default
        openstack.proxy:
          cpu: 4
          ram: 4096
          disk_profile: small
          net_profile: default
        opencontrail.control:
          cpu: 8
          ram: 16384
          disk_profile: small
          net_profile: default
        opencontrail.analytics:
          cpu: 8
          ram: 16384
          disk_profile: large
          net_profile: default
        stacklight.log:
          cpu: 4
          ram: 4096
          disk_profile: xxlarge
          net_profile: default
        stacklight.server:
          cpu: 4
          ram: 4094
          disk_profile: small
          net_profile: default
        stacklight.telemetry:
          cpu: 4
          ram: 4096
          disk_profile: xxlarge
          net_profile: default
      cluster:
        internal:
          node:
            prx02:
              provider: kvm03.${_param:cluster_domain}
  linux:
    network:
      interface:
        eth0:
          enabled: true
          proto: manual
          mtu: 9000
        eth1:
          enabled: true
          type: slave
          proto: manual
          mtu: 9000
          master: bond0
        eth2:
          enabled: true
          type: slave
          proto: manual
          mtu: 9000
          master: bond0
        eth3:
          enabled: true
          type: slave
          proto: manual
          mtu: 9000
          master: bond0
        eth4:
          enabled: true
          type: slave
          proto: manual
          mtu: 9000
          master: bond0
        eth5:
          enabled: true
          type: slave
          proto: manual
          mtu: 9000
          master: bond0
        bond0:
          enabled: true
          proto: manual
          type: bond
          use_interfaces:
          - eth1
          - eth2
          - eth3
          - eth4
          - eth5
          slaves: eth1 eth2 eth3 eth4 eth5
          mode: 802.3ad
          lacp_rate: slow
          hashing-algorithm: layer2+3
          mimon: 100
        bond0.1361:
          enabled: true
          type: vlan
          proto: manual
          mtu: 9000
          use_interfaces:
          - bond0
        br-admin:
          enabled: true
          name_servers:
          - 172.17.32.3
          - 8.8.8.8
          - 8.8.4.4
          type: bridge
          mtu: 9000
          use_interfaces:
          - eth0
        br-mgmt:
          enabled: true
          type: bridge
          proto: manual
          mtu: 9000
          use_interfaces:
          - bond0.1361
    network_manager:
      disable: true
  libvirt:
    server:
      enabled: true
      kvm_pkgs: ['qemu','qemu-utils']
      network:
        admin:
          xml: |
            <network>
              <name>admin</name>
                <forward mode='bridge'>
                  <interface dev='br-admin'/>
                </forward>
            </network>
        mgmt:
          xml: |
            <network>
              <name>mgmt</name>
                <forward mode='bridge'>
                  <interface dev='br-mgmt'/>
                </forward>
            </network>

  virt:
    nic:
      default:
        eth0:
          bridge: br-admin
          model: virtio
        eth1:
          bridge: br-mgmt
          model: virtio

  ##FIXME
  # linux:
  #   network:
  #     interface:
  #       eth0:
  #         enabled: true
  #         type: eth
  #         proto: manual
  #       eth1:
  #         enabled: true
  #         type: eth
  #         proto: manual
  #       eth2:
  #         enabled: true
  #         type: eth
  #         proto: manual
  #       br_mgm:
  #         enabled: true
  #         proto: static
  #         type: bridge
  #         address: ${_param:deploy_address}
  #         netmask: 255.255.255.0
  #         use_interfaces:
  #         - eth0
  #       bond0:
  #         enabled: true
  #         proto: manual
  #         type: bond
  #         use_interfaces:
  #         - eth1
  #         - eth2
  #         slaves: eth1 eth2
  #         mode: active-backup
  #       br_ctl:
  #         enabled: true
  #         type: bridge
  #         proto: static
  #         address: ${_param:single_address}
  #         gateway: 172.17.36.1
  #         netmask: 255.255.255.128
  #         name_servers:
  #         - 172.17.32.3
  #         - 8.8.8.8
  #         use_interfaces:
  #         - bond0
